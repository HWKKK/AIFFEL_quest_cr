import json
import os
import google.generativeai as genai
import re
from dotenv import load_dotenv

load_dotenv()

# Google Gemini API í‚¤ ì„¤ì •
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

genai.configure(api_key=api_key)

# ë©˜í†  ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
with open("mentors.json", "r", encoding="utf-8") as file:
    mentors = json.load(file)

def split_sentences(text, max_length=100):
    """ê¸´ ë¬¸ì¥ì„ ì ì ˆí•œ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    sentences = re.split(r'(?<=[.!?])\s+', text)  # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°
    chunks = []
    current_chunk = ""

    for sentence in sentences:
        if len(current_chunk) + len(sentence) < max_length:
            current_chunk += sentence + " "
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence + " "

    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks

def get_mentor_response(mentor_id: str, user_question: str):
    """Google Gemini APIë¥¼ í™œìš©í•˜ì—¬ íŠ¹ì • ë©˜í† ì²˜ëŸ¼ ë‹µë³€ ìƒì„±"""
    if mentor_id not in mentors:
        return {"responses": ["ì´ ë©˜í† ì— ëŒ€í•œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."]}

    mentor = mentors[mentor_id]

    # âœ… ë” ëŒ€í™”í˜• ìŠ¤íƒ€ì¼ë¡œ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸
    prompt = (
        f"ë„ˆëŠ” {mentor['name']}ì´ì•¼. "
        f"ë„ˆì˜ ëŒ€í™” ìŠ¤íƒ€ì¼ì€ {mentor['style']}ì´ì•¼. "
        f"ì§ˆë¬¸ìëŠ” ë„ˆì˜ ì œìì´ë©°, ë„ˆëŠ” ë„ˆì˜ {mentor['category']} ëŠ¥ë ¥ì„ ê°€ë¥´ì³. "
        f"ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ë©° ì„¤ëª…í•´ì¤˜. "
        f"ë„ˆë¬´ ê¸´ ë‹µë³€ì„ í•˜ì§€ ë§ê³ , í•œ ë²ˆì— ì§§ì€ ë©”ì‹œì§€ë¡œ ëŒ€ë‹µí•˜ê³  ë‹¤ìŒ ë©”ì‹œì§€ë¥¼ ê¸°ë‹¤ë ¤ì¤˜. "
        f"ë²ˆí˜¸ ë§¤ê¸°ê¸°ëŠ” í”¼í•˜ê³ , ë§ˆì¹˜ ëŒ€í™”í•˜ë“¯ ë‹µë³€í•´ì¤˜. "
        f"\n\nì§ˆë¬¸: {user_question}"
    )

    try:
        print(f"ğŸ’¡ [DEBUG] Gemini API í˜¸ì¶œ ì‹œì‘: {mentor['name']}, ì§ˆë¬¸: {user_question}")

        # Gemini ëª¨ë¸ ì„¸ì…˜ ìƒì„±
        model = genai.GenerativeModel("gemini-2.0-flash")
        chat = model.start_chat()

        response = chat.send_message(prompt)

        # âœ… ë¬¸ì¥ì„ ë‚˜ëˆ„ì–´ ì—¬ëŸ¬ ê°œì˜ ì‘ë‹µìœ¼ë¡œ ë°˜í™˜
        split_responses = split_sentences(response.text.strip(), max_length=100)

        return {"responses": split_responses}  # âœ… ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜

    except Exception as e:
        print(f"âŒ [ERROR] Gemini API ì˜¤ë¥˜: {e}")
        return {"responses": [f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"]}
